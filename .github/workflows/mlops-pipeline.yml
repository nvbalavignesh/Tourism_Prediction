name: Tourism Package Prediction MLOps Pipeline

on:
  push:
    branches:
      - main  # Automatically triggers on push to the main branch
  workflow_dispatch:  # Allows manual triggering
    inputs:
      debug_enabled:
        description: 'Enable debugging'
        required: false
        default: 'false'

env:
  PYTHON_VERSION: '3.9'
  HF_HOME: /tmp/.cache/huggingface

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tourism_project/requirements.txt
          
      - name: Create data directory
        run: |
          mkdir -p tourism_project/data
          
      - name: Copy dataset to data directory
        run: |
          cp tourism.csv tourism_project/data/tourism.csv
          
      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd tourism_project/model_building
          python data_register.py

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tourism_project/requirements.txt
          
      - name: Run Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd tourism_project/model_building
          python prep.py

  model-training:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tourism_project/requirements.txt
          
      - name: Start MLflow Server
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 &
          sleep 10  # Wait for MLflow server to start
          
      - name: Model Building and Training
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          MLFLOW_TRACKING_URI: http://localhost:5000
        run: |
          cd tourism_project/model_building
          python train.py
          
      - name: Archive MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-artifacts
          path: mlruns/
          retention-days: 30

  deploy-hosting:
    runs-on: ubuntu-latest
    needs: [model-training, data-prep, register-dataset]
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tourism_project/requirements.txt
          
      - name: Deploy to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd tourism_project/hosting
          python hosting.py
          
      - name: Deployment Status
        run: |
          echo "üöÄ Deployment completed successfully!"
          echo "üì± Your Streamlit app should be available at: https://huggingface.co/spaces/itsjarvis/Tourism-Prediction"

  notify-completion:
    runs-on: ubuntu-latest
    needs: [register-dataset, data-prep, model-training, deploy-hosting]
    if: always()
    steps:
      - name: Pipeline Status Summary
        run: |
          echo "üìä MLOps Pipeline Execution Summary:"
          echo "‚úÖ Dataset Registration: ${{ needs.register-dataset.result }}"
          echo "‚úÖ Data Preparation: ${{ needs.data-prep.result }}"
          echo "‚úÖ Model Training: ${{ needs.model-training.result }}"
          echo "‚úÖ Deployment: ${{ needs.deploy-hosting.result }}"
          
          if [ "${{ needs.register-dataset.result }}" = "success" ] && 
             [ "${{ needs.data-prep.result }}" = "success" ] && 
             [ "${{ needs.model-training.result }}" = "success" ] && 
             [ "${{ needs.deploy-hosting.result }}" = "success" ]; then
            echo "üéâ All pipeline stages completed successfully!"
          else
            echo "‚ùå Some pipeline stages failed. Check the logs above."
          fi